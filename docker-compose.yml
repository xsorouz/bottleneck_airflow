# ============================================================================
# üì¶ Docker Compose - Projet BottleNeck avec Apache Airflow, MinIO, PostgreSQL
# Architecture professionnelle avec ex√©cution Celery + Monitoring Flower
# ============================================================================

# (version supprim√©e car d√©pr√©ci√©e)

# ============================================================================
# üóÉÔ∏è Volumes persistants
# ============================================================================
volumes:
  postgres-data:         # Donn√©es PostgreSQL (backend Airflow)
  airflow-logs:          # Logs Airflow
  minio-data:            # Donn√©es MinIO (inputs, outputs, logs)

# ============================================================================
# üåê R√©seau interne
# ============================================================================
networks:
  airflow_net:
    driver: bridge

# ============================================================================
# üöÄ Services Docker
# ============================================================================
services:

  # --------------------------------------------------------------------------
  # üóÑÔ∏è PostgreSQL - Base Airflow
  # --------------------------------------------------------------------------
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - airflow_net
    restart: unless-stopped

  # --------------------------------------------------------------------------
  # ‚òÅÔ∏è MinIO - Stockage compatible S3
  # --------------------------------------------------------------------------
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --address ":9000" --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: admin1234
    volumes:
      - minio-data:/data
    networks:
      - airflow_net
    restart: unless-stopped

  # --------------------------------------------------------------------------
  # üî• Redis - File d'attente Celery
  # --------------------------------------------------------------------------
  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    networks:
      - airflow_net
    restart: unless-stopped

  # --------------------------------------------------------------------------
  # ‚úàÔ∏è Airflow Webserver
  # --------------------------------------------------------------------------
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.9.0-python3.10
    command: webserver
    depends_on:
      - postgres
      - redis
      - airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__WEBSERVER__SECRET_KEY: my_secret_key
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./tests:/opt/airflow/tests
      - ./data:/opt/airflow/data
      - airflow-logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    networks:
      - airflow_net
    restart: unless-stopped

  # --------------------------------------------------------------------------
  # ‚è±Ô∏è Airflow Scheduler
  # --------------------------------------------------------------------------
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.9.0-python3.10
    command: scheduler
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./tests:/opt/airflow/tests
      - ./data:/opt/airflow/data
      - airflow-logs:/opt/airflow/logs
    networks:
      - airflow_net
    restart: unless-stopped

  # --------------------------------------------------------------------------
  # ‚öôÔ∏è Airflow Worker
  # --------------------------------------------------------------------------
  airflow-worker:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.9.0-python3.10
    command: celery worker
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./tests:/opt/airflow/tests
      - ./data:/opt/airflow/data
      - airflow-logs:/opt/airflow/logs
    networks:
      - airflow_net
    restart: unless-stopped

  # --------------------------------------------------------------------------
  # üìä Flower - Monitoring Celery
  # --------------------------------------------------------------------------
  flower:
    build:
      context: .
      dockerfile: Dockerfile
    image: apache/airflow:2.9.0-python3.10
    command: celery flower
    depends_on:
      - redis
      - airflow-worker
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    ports:
      - "5555:5555"
    networks:
      - airflow_net
    restart: unless-stopped
