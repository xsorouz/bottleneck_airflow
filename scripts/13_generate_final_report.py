# === Script 13 - G√©n√©ration du rapport final et upload dans MinIO ===
# Ce script synth√©tise tout le pipeline et archive le rapport dans MinIO.

import os
import sys
import duckdb
import pandas as pd
import boto3
from botocore.exceptions import ClientError
from pathlib import Path
from loguru import logger
import warnings

warnings.filterwarnings("ignore")

# ============================================================================== 
# üîß Initialisation des chemins et logs
# ============================================================================== 
AIRFLOW_LOG_PATH = os.getenv("AIRFLOW_LOG_PATH", "logs")
LOGS_PATH = Path(AIRFLOW_LOG_PATH)
LOGS_PATH.mkdir(parents=True, exist_ok=True)

LOG_FILE = LOGS_PATH / "rapport_final.log"
logger.remove()
logger.add(sys.stdout, level="INFO")
logger.add(LOG_FILE, level="INFO", rotation="500 KB")

# ============================================================================== 
# üìä Fonction principale : g√©n√©ration et upload du rapport final
# ============================================================================== 
def main():
    # Connexion √† DuckDB
    try:
        con = duckdb.connect("data/bottleneck.duckdb")
        logger.success("‚úÖ Connexion √† DuckDB √©tablie.")
    except Exception as e:
        logger.error(f"‚ùå Connexion √† DuckDB √©chou√©e : {e}")
        sys.exit(1)

    # Collecte des m√©triques
    try:
        logger.info("üìã R√©cup√©ration des m√©triques du pipeline...")

        metrics = {}
        metrics["ERP_brut"] = pd.read_csv("data/raw/erp.csv").shape[0]
        metrics["Web_brut"] = pd.read_csv("data/raw/web.csv").shape[0]
        metrics["Liaison_brut"] = pd.read_csv("data/raw/liaison.csv").shape[0]

        metrics["ERP_nettoye"] = con.execute("SELECT COUNT(*) FROM erp_clean").fetchone()[0]
        metrics["Web_nettoye"] = con.execute("SELECT COUNT(*) FROM web_clean").fetchone()[0]
        metrics["Liaison_nettoye"] = con.execute("SELECT COUNT(*) FROM liaison_clean").fetchone()[0]

        metrics["ERP_dedup"] = con.execute("SELECT COUNT(*) FROM erp_dedup").fetchone()[0]
        metrics["Web_dedup"] = con.execute("SELECT COUNT(*) FROM web_dedup").fetchone()[0]
        metrics["Liaison_dedup"] = con.execute("SELECT COUNT(*) FROM liaison_dedup").fetchone()[0]

        metrics["Fusion"] = con.execute("SELECT COUNT(*) FROM fusion").fetchone()[0]
        metrics["CA_total"] = con.execute("SELECT ca_total FROM ca_total").fetchone()[0]
        metrics["Produits_CA"] = con.execute("SELECT COUNT(*) FROM ca_par_produit").fetchone()[0]
        metrics["Vins_millesimes"] = pd.read_csv("data/outputs/vins_millesimes.csv").shape[0]

        logger.success("‚úÖ Donn√©es du pipeline r√©cup√©r√©es.")
    except Exception as e:
        logger.error(f"‚ùå Erreur de r√©cup√©ration des donn√©es : {e}")
        sys.exit(1)

    # Construction du rapport
    try:
        df_report = pd.DataFrame([
            {"√âtape": "Brut - ERP", "R√©sultat": metrics["ERP_brut"], "Attendu": ""},
            {"√âtape": "Brut - Web", "R√©sultat": metrics["Web_brut"], "Attendu": ""},
            {"√âtape": "Brut - Liaison", "R√©sultat": metrics["Liaison_brut"], "Attendu": ""},
            {"√âtape": "Nettoy√© - ERP", "R√©sultat": metrics["ERP_nettoye"], "Attendu": ""},
            {"√âtape": "Nettoy√© - Web", "R√©sultat": metrics["Web_nettoye"], "Attendu": ""},
            {"√âtape": "Nettoy√© - Liaison", "R√©sultat": metrics["Liaison_nettoye"], "Attendu": ""},
            {"√âtape": "D√©doublonn√© - ERP", "R√©sultat": metrics["ERP_dedup"], "Attendu": "825"},
            {"√âtape": "D√©doublonn√© - Web", "R√©sultat": metrics["Web_dedup"], "Attendu": "714"},
            {"√âtape": "D√©doublonn√© - Liaison", "R√©sultat": metrics["Liaison_dedup"], "Attendu": "825"},
            {"√âtape": "Fusion finale", "R√©sultat": metrics["Fusion"], "Attendu": "714"},
            {"√âtape": "Produits CA", "R√©sultat": metrics["Produits_CA"], "Attendu": "573"},
            {"√âtape": "CA Total (‚Ç¨)", "R√©sultat": round(metrics["CA_total"], 2), "Attendu": "387837.60"},
            {"√âtape": "Vins Mill√©sim√©s", "R√©sultat": metrics["Vins_millesimes"], "Attendu": "30"},
        ])

        OUTPUTS_PATH = Path("data/outputs")
        OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)

        df_report.to_csv(OUTPUTS_PATH / "rapport_final.csv", index=False)
        df_report.to_excel(OUTPUTS_PATH / "rapport_final.xlsx", index=False)
        logger.success("üìÑ Rapport final export√©.")
    except Exception as e:
        logger.error(f"‚ùå Erreur export rapport : {e}")
        sys.exit(1)

    # Upload MinIO
    try:
        s3_client = boto3.client(
            "s3",
            endpoint_url="http://host.docker.internal:9000",
            aws_access_key_id="AKIAIOSFODNN7EXAMPLE",
            aws_secret_access_key="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY",
            region_name="us-east-1",
        )
        for filename in ["rapport_final.csv", "rapport_final.xlsx"]:
            local_file = OUTPUTS_PATH / filename
            s3_key = f"data/outputs/{filename}"
            s3_client.upload_file(str(local_file), "bottleneck", s3_key)
            logger.success(f"üöÄ Upload r√©ussi : {filename} vers {s3_key}")
    except Exception as e:
        logger.error(f"‚ùå Erreur upload MinIO : {e}")
        sys.exit(1)

    logger.success("üéØ Rapport final complet archiv√© avec succ√®s dans MinIO.")

# ============================================================================== 
# üöÄ Point d'entr√©e
# ============================================================================== 
if __name__ == "__main__":
    main()
