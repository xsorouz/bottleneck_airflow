# === Script 05 - Nettoyage complet et pr√©paration des fichiers (DuckDB + CSV) ===
# Ce script lit les fichiers CSV bruts depuis 'data/inputs/', applique un nettoyage m√©tier,
# enregistre les fichiers propres dans 'data/outputs/' et cr√©e des tables DuckDB persistantes.

import os
import sys
import warnings
from pathlib import Path
import pandas as pd
import duckdb
from loguru import logger

# ============================================================================== 
# üîß Initialisation des chemins et logs
# ============================================================================== 
warnings.filterwarnings("ignore")

AIRFLOW_LOG_PATH = os.getenv("AIRFLOW_LOG_PATH", "logs")
LOGS_PATH = Path(AIRFLOW_LOG_PATH)
LOGS_PATH.mkdir(parents=True, exist_ok=True)

LOG_FILE = LOGS_PATH / "clean_data.log"
logger.remove()
logger.add(sys.stdout, level="INFO")
logger.add(LOG_FILE, level="INFO", rotation="500 KB")

# ============================================================================== 
# üíº Fonction principale encapsulant toute la logique
# ============================================================================== 
def main():
    # üìÅ Chemins des donn√©es
    INPUTS_PATH = Path("data/inputs")
    OUTPUTS_PATH = Path("data/outputs")
    DB_PATH = Path("data/bottleneck.duckdb")

    INPUTS_PATH.mkdir(parents=True, exist_ok=True)
    OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)

    # üìÇ Chargement des fichiers CSV bruts
    erp_csv = INPUTS_PATH / "erp.csv"
    web_csv = INPUTS_PATH / "web.csv"
    liaison_csv = INPUTS_PATH / "liaison.csv"

    try:
        df_erp = pd.read_csv(erp_csv)
        df_web = pd.read_csv(web_csv)
        df_liaison = pd.read_csv(liaison_csv)

        logger.info(f"ERP     : {len(df_erp)} lignes (lignes vides : {df_erp.isnull().all(axis=1).sum()})")
        logger.info(f"WEB     : {len(df_web)} lignes (lignes vides : {df_web.isnull().all(axis=1).sum()})")
        logger.info(f"LIAISON : {len(df_liaison)} lignes (lignes vides : {df_liaison.isnull().all(axis=1).sum()})")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du chargement initial : {e}")
        return

    # ü¶Ü Nettoyage m√©tier avec DuckDB
    try:
        con = duckdb.connect(str(DB_PATH))
        logger.info("‚úÖ Connexion DuckDB √©tablie.")

        con.execute("""
            CREATE OR REPLACE TABLE erp_clean AS
            SELECT * FROM read_csv_auto('data/inputs/erp.csv')
            WHERE product_id IS NOT NULL
              AND onsale_web IS NOT NULL
              AND price IS NOT NULL AND price > 0
              AND stock_quantity IS NOT NULL
              AND stock_status IS NOT NULL
        """)
        logger.success("‚úÖ Table 'erp_clean' cr√©√©e.")

        con.execute("""
            CREATE OR REPLACE TABLE web_clean AS
            SELECT * FROM read_csv_auto('data/inputs/web.csv')
            WHERE sku IS NOT NULL
        """)
        logger.success("‚úÖ Table 'web_clean' cr√©√©e.")

        con.execute("""
            CREATE OR REPLACE TABLE liaison_clean AS
            SELECT * FROM read_csv_auto('data/inputs/liaison.csv')
            WHERE product_id IS NOT NULL
              AND id_web IS NOT NULL
        """)
        logger.success("‚úÖ Table 'liaison_clean' cr√©√©e.")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du nettoyage avec DuckDB : {e}")
        return

    # üíæ Export des donn√©es nettoy√©es
    try:
        con.execute("COPY erp_clean TO 'data/outputs/erp_clean.csv' (HEADER, DELIMITER ',')")
        con.execute("COPY web_clean TO 'data/outputs/web_clean.csv' (HEADER, DELIMITER ',')")
        con.execute("COPY liaison_clean TO 'data/outputs/liaison_clean.csv' (HEADER, DELIMITER ',')")
        logger.success("‚úÖ Donn√©es nettoy√©es export√©es dans 'data/outputs/'.")
    except Exception as e:
        logger.error(f"‚ùå Erreur d'export CSV : {e}")
        return

    # üìä R√©sum√© statistique
    try:
        resume_df = pd.DataFrame({
            "source": ["erp", "web", "liaison"],
            "nb_lignes_initiales": [len(df_erp), len(df_web), len(df_liaison)],
            "nb_apres_nettoyage": [
                con.execute("SELECT COUNT(*) FROM erp_clean").fetchone()[0],
                con.execute("SELECT COUNT(*) FROM web_clean").fetchone()[0],
                con.execute("SELECT COUNT(*) FROM liaison_clean").fetchone()[0]
            ]
        })
        resume_df["nb_exclues"] = resume_df["nb_lignes_initiales"] - resume_df["nb_apres_nettoyage"]
        resume_df.to_csv(OUTPUTS_PATH / "resume_stats.csv", index=False)
        logger.success("üìà Statistiques export√©es : resume_stats.csv")
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du r√©sum√© statistique : {e}")
        return

    logger.success("üéØ Nettoyage termin√© avec succ√®s.")

# ============================================================================== 
# üöÄ Ex√©cution principale
# ============================================================================== 
if __name__ == "__main__":
    main()
